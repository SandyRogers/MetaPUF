import pandas as pd


def remove_doubtful_protein_groups(proteinGroups):
    """
    remove doubtful protein groups (only keeps the confident ones)
    remove protein groups which contains human and contanminat proteins
    """
    PGLists = proteinGroups.replace(' ', '').split(';')
    PGAfterfilter = ""
    for pg in PGLists:
        if pg.endswith('(Confident)'):
            tmp_pg = pg[0:-11].replace(' ', '').split(',')
            is_huamn_crap = False
            PGRemovalHumanAndCrap = ""
            for protein in tmp_pg:
                if protein.startswith('MGYP9'):
                    is_huamn_crap = True
                    break
                
                PGRemovalHumanAndCrap += protein
                PGRemovalHumanAndCrap += ","

            if PGRemovalHumanAndCrap.endswith(','):
                PGRemovalHumanAndCrap = PGRemovalHumanAndCrap[0:-1]
            
            if is_huamn_crap == False:
                PGAfterfilter += PGRemovalHumanAndCrap
                PGAfterfilter += ";"

    if PGAfterfilter.endswith(';'):
        PGAfterfilter = PGAfterfilter[0:-1]

    return PGAfterfilter


def count_validated_protein_groups(processedPG):
    # after filtering, remove these empty protein groups
    PGCount = 0
    if len(processedPG) > 0:
        PGCount = len(processedPG.split(';'))

    return PGCount


def get_positions(positions):
    # getting the peptide start positions for identified proteins
    processed_positions = ""
    positions = positions.replace(' ', '').split(';')
    for p in positions:
        if p.endswith(')'):
            processed_positions += p.split('(')[1][0:-1]
        else:
            processed_positions += p
        processed_positions += ";"

    if processed_positions.endswith(";"):
        processed_positions = processed_positions[0:-1]

    return processed_positions


def remove_human_crap_protein_groups(proteinGroup):
    # remove protein groups which contains human and contanminat proteins
    PGRemovalHumanAndCrap = ""
    tmp_pg = proteinGroup.replace(' ', '').split(',')
    is_huamn_crap = False
    for protein in tmp_pg:
        if protein.startswith('MGYP9'):
            is_huamn_crap = True
            break
        
        PGRemovalHumanAndCrap += protein
        PGRemovalHumanAndCrap += ","

    if PGRemovalHumanAndCrap.endswith(','):
        PGRemovalHumanAndCrap = PGRemovalHumanAndCrap[0:-1]
    
    if is_huamn_crap == True:
        PGRemovalHumanAndCrap = ""

    return PGRemovalHumanAndCrap


# def create_dict_for_spectrum_counting(protein_report):
#     # creating a dictionary for protein groups and the corresponding spectrum counting
#     protein = pd.read_csv(protein_report, sep='\t')[['Protein Group','Spectrum Counting']]
#     protein['Processed Protein Group'] = protein['Protein Group'].apply(remove_human_crap_protein_groups)
#     df = protein[['Processed Protein Group', 'Spectrum Counting']]
#     df = df.drop_duplicates(subset='Processed Protein Group', keep="last")
#     df = df.set_index('Processed Protein Group').to_dict(orient='index')

#     return df


def get_spectrum_counting(protein_report):
    # getting the Specturm Countings for protein (Main Accession) from protein_reports generated from PeptideShaker
    protein = pd.read_csv(protein_report, sep='\t')[['Main Accession','#Validated PSMs','Spectrum Counting']]
    protein = protein[protein['#Validated PSMs'] > 0][['Main Accession','Spectrum Counting']]
    df = protein.drop_duplicates(subset='Main Accession', keep="last")
    df = df.rename(columns={"Main Accession": "Protein"})

    return df


# def apply_SC(peptides, SC_df):
#     return pd.Series([get_spectrum_counting(ppg, SC_df) for ppg in peptides['Processed Protein Groups']])


def remove_irrelevant_proteins(proteins, positions, proteinGroups):
    # remove the proteins are not exsiting in the proccessed protein groups
    PG_proteins = []
    for pg in proteinGroups:
        for p in pg.replace(' ', '').split(','):
            PG_proteins.append(p)
    PG_proteins = list(set(PG_proteins))

    temp_proteinIDs = []
    temp_positions = []

    for i in range(len(proteins)):
        if proteins[i] in PG_proteins:
            temp_proteinIDs.append(proteins[i])
            temp_positions.append(positions[i])

    return temp_proteinIDs, temp_positions


def get_track_beds(peptide_report, protein_report, save_file_name, pxd_id):
    """
    Post-processing the reports based on peptide and protein reports generated by PeptideShaker.
    :param peptide_report: the peptide report file generated from PeptideShaker
    :param protein_report: the protein report file generated from PeptideShaker
    :param save_file_name: the post processed report file name and path
    :param pxd_id: the PRIDE accession number
    """

    peptides = pd.read_csv(peptide_report, sep='\t')[['Protein(s)','Protein Group(s)','Sequence','Position','#Validated PSMs']]
    peptides = peptides[peptides['#Validated PSMs'] > 0]

    peptides['Processed Protein Groups'] = peptides['Protein Group(s)'].apply(remove_doubtful_protein_groups)
    peptides['Validated Protein Groups'] = peptides['Processed Protein Groups'].apply(count_validated_protein_groups)
    peptides = peptides[peptides['Validated Protein Groups'] > 0]
    peptides['Processed Position'] = peptides['Position'].apply(get_positions)
    peptides = peptides.reset_index()

    SC_df = get_spectrum_counting(protein_report)

    proteins = peptides['Protein(s)'].str.replace(' ', '').str.split(';')
    proteinGroups = peptides['Processed Protein Groups'].str.replace(' ', '').str.split(';')
    positions = peptides['Processed Position'].str.replace(' ', '').str.split(';')
    sequences = peptides['Sequence']
    validated_psms = peptides['#Validated PSMs']
    validated_PG = peptides['Validated Protein Groups']
    processed_PG = peptides['Processed Protein Groups']


    processed_proteins = []
    processed_positions = []
    for i in range(len(proteins)):
        temp_proteinIDs, temp_positions = remove_irrelevant_proteins(proteins[i], positions[i], proteinGroups[i])
        processed_proteins.append(temp_proteinIDs)
        processed_positions.append(temp_positions)

    output_proteins = []
    output_sequences = []
    output_positions = []
    output_validated_psms = []
    output_validated_PG = []
    output_processed_PG = []
    for i in range(len(processed_proteins)):
        protein_list = processed_proteins[i]
        seq = sequences[i]
        pos_list = processed_positions[i]
        valid_psm = validated_psms[i]
        valid_PG = validated_PG[i]
        pg = processed_PG[i]

        for j in range(len(protein_list)):
            output_proteins.append(protein_list[j])
            output_sequences.append(seq)
            output_positions.append(pos_list[j])
            output_validated_psms.append(valid_psm)
            output_validated_PG.append(valid_PG)
            output_processed_PG.append(pg)


    output = pd.DataFrame()
    output['Protein'] = output_proteins
    output['Sequence'] = output_sequences
    output['Position'] = output_positions
    output['Validated PSMs'] = output_validated_psms
    output['Validated Protein Groups'] = output_validated_PG
    output['Processed Protein Groups'] = output_processed_PG
    
    output = output.merge(SC_df, how='left', on='Protein')

    # the below part is not needed, we will keep the proteins which exist in different protein groups
    # seq_count = []
    # for i in range(len(output_proteins)):
    #     count = 0
    #     for j in range(i, len(output_proteins)):
    #         if output_proteins[i] == output_proteins[j] and output_sequences[i] == output_sequences[j]:
    #             count += 1
    #     seq_count.append(count)

    # output['Protein Sequence Counts'] = seq_count
    # output = output[output['Protein Sequence Counts'] == 1]

    groupby_sequence = output.groupby(['Sequence']).count()['Protein']
    seq_count = pd.DataFrame()
    seq_count['Sequence'] = groupby_sequence.index.to_list()
    seq_count['#Proteins'] = groupby_sequence.values
    output = output.merge(seq_count, how='left', on='Sequence')

    output['PXD ID'] = pxd_id
    output['PRIDE Link'] = 'ebi.ac.uk/pride/archive/projects/' + pxd_id

    save_columns = ['Protein','Sequence','Position','#Proteins','Validated Protein Groups','Validated PSMs','Spectrum Counting','Processed Protein Groups','PXD ID','PRIDE Link']
    output[save_columns].to_csv(save_file_name, index=False)