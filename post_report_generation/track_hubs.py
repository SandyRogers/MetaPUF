import pandas as pd


def remove_doubtful_protein_groups(proteinGroups):
    """
    remove doubtful protein groups (only keeps the confident ones)
    remove protein groups which contains human and contanminat proteins
    """
    PGLists = proteinGroups.replace(" ", "").split(";")
    PGAfterfilter = ""
    for pg in PGLists:
        if pg.endswith("(Confident)"):
            tmp_pg = pg[0:-11].replace(" ", "").split(",")
            is_huamn_crap = False
            PGRemovalHumanAndCrap = ""
            for protein in tmp_pg:
                if protein.startswith("MGYP9"):
                    is_huamn_crap = True
                    break

                PGRemovalHumanAndCrap += protein
                PGRemovalHumanAndCrap += ","

            if PGRemovalHumanAndCrap.endswith(","):
                PGRemovalHumanAndCrap = PGRemovalHumanAndCrap[0:-1]

            if is_huamn_crap == False:
                PGAfterfilter += PGRemovalHumanAndCrap
                PGAfterfilter += ";"

    if PGAfterfilter.endswith(";"):
        PGAfterfilter = PGAfterfilter[0:-1]

    return PGAfterfilter


def count_validated_protein_groups(processedPG):
    # after filtering, remove these empty protein groups
    PGCount = 0
    if len(processedPG) > 0:
        PGCount = len(processedPG.split(";"))

    return PGCount


def get_positions(positions):
    # getting the peptide start positions for identified proteins
    processed_positions = ""
    positions = positions.replace(" ", "").split(";")
    for p in positions:
        if p.endswith(")"):
            processed_positions += p.split("(")[1][0:-1]
        else:
            processed_positions += p
        processed_positions += ";"

    if processed_positions.endswith(";"):
        processed_positions = processed_positions[0:-1]

    return processed_positions


def remove_human_crap_protein_groups(proteinGroup):
    # remove protein groups which contains human and contanminat proteins
    PGRemovalHumanAndCrap = ""
    tmp_pg = proteinGroup.replace(" ", "").split(",")
    is_huamn_crap = False
    for protein in tmp_pg:
        if protein.startswith("MGYP9"):
            is_huamn_crap = True
            break

        PGRemovalHumanAndCrap += protein
        PGRemovalHumanAndCrap += ","

    if PGRemovalHumanAndCrap.endswith(","):
        PGRemovalHumanAndCrap = PGRemovalHumanAndCrap[0:-1]

    if is_huamn_crap == True:
        PGRemovalHumanAndCrap = ""

    return PGRemovalHumanAndCrap


# def create_dict_for_spectrum_counting(protein_report):
#     # creating a dictionary for protein groups and the corresponding spectrum counting
#     protein = pd.read_csv(protein_report, sep='\t')[['Protein Group','Spectrum Counting']]
#     protein['Processed Protein Group'] = protein['Protein Group'].apply(remove_human_crap_protein_groups)
#     df = protein[['Processed Protein Group', 'Spectrum Counting']]
#     df = df.drop_duplicates(subset='Processed Protein Group', keep="last")
#     df = df.set_index('Processed Protein Group').to_dict(orient='index')

#     return df


def get_spectrum_counting(protein_report):
    # getting the Specturm Countings for protein (Main Accession) from protein_reports generated from PeptideShaker
    protein = pd.read_csv(protein_report, sep="\t")[
        ["Main Accession", "#Validated PSMs", "Spectrum Counting"]
    ]
    protein = protein[protein["#Validated PSMs"] > 0][
        ["Main Accession", "Spectrum Counting"]
    ]
    df = protein.drop_duplicates(subset="Main Accession", keep="last")
    df = df.rename(columns={"Main Accession": "Protein"})

    return df


# def apply_SC(peptides, SC_df):
#     return pd.Series([get_spectrum_counting(ppg, SC_df) for ppg in peptides['Processed Protein Groups']])


def remove_irrelevant_proteins(proteins, positions, proteinGroups):
    # remove the proteins are not exsiting in the proccessed protein groups
    PG_proteins = []
    for pg in proteinGroups:
        for p in pg.replace(" ", "").split(","):
            PG_proteins.append(p)
    PG_proteins = list(set(PG_proteins))

    temp_proteinIDs = []
    temp_positions = []

    for i in range(len(proteins)):
        if proteins[i] in PG_proteins:
            temp_proteinIDs.append(proteins[i])
            temp_positions.append(positions[i])

    return temp_proteinIDs, temp_positions


def get_track_beds(peptide_report, protein_report, save_file_name, pxd_id):
    """
    Post-processing the reports based on peptide and protein reports generated by PeptideShaker.
    :param peptide_report: the peptide report file generated from PeptideShaker
    :param protein_report: the protein report file generated from PeptideShaker
    :param save_file_name: the post processed report file name and path
    :param pxd_id: the PRIDE accession number
    """

    peptides = pd.read_csv(peptide_report, sep="\t")[
        ["Protein(s)", "Protein Group(s)", "Sequence", "Position", "#Validated PSMs"]
    ]
    peptides = peptides[peptides["#Validated PSMs"] > 0]

    peptides["Processed Protein Groups"] = peptides["Protein Group(s)"].apply(
        remove_doubtful_protein_groups
    )
    peptides["Validated Protein Groups"] = peptides["Processed Protein Groups"].apply(
        count_validated_protein_groups
    )
    peptides = peptides[peptides["Validated Protein Groups"] > 0]
    peptides["Processed Position"] = peptides["Position"].apply(get_positions)
    peptides = peptides.reset_index()

    SC_df = get_spectrum_counting(protein_report)

    proteins = peptides["Protein(s)"].str.replace(" ", "").str.split(";")
    proteinGroups = (
        peptides["Processed Protein Groups"].str.replace(" ", "").str.split(";")
    )
    positions = peptides["Processed Position"].str.replace(" ", "").str.split(";")
    sequences = peptides["Sequence"]
    validated_psms = peptides["#Validated PSMs"]
    validated_PG = peptides["Validated Protein Groups"]
    processed_PG = peptides["Processed Protein Groups"]

    processed_proteins = []
    processed_positions = []
    for i in range(len(proteins)):
        temp_proteinIDs, temp_positions = remove_irrelevant_proteins(
            proteins[i], positions[i], proteinGroups[i]
        )
        processed_proteins.append(temp_proteinIDs)
        processed_positions.append(temp_positions)

    output_proteins = []
    output_sequences = []
    output_positions = []
    output_validated_psms = []
    output_validated_PG = []
    output_processed_PG = []
    for i in range(len(processed_proteins)):
        protein_list = processed_proteins[i]
        seq = sequences[i]
        pos_list = processed_positions[i]
        valid_psm = validated_psms[i]
        valid_PG = validated_PG[i]
        pg = processed_PG[i]

        for j in range(len(protein_list)):
            output_proteins.append(protein_list[j])
            output_sequences.append(seq)
            output_positions.append(pos_list[j])
            output_validated_psms.append(valid_psm)
            output_validated_PG.append(valid_PG)
            output_processed_PG.append(pg)

    output = pd.DataFrame()
    output["Protein"] = output_proteins
    output["Sequence"] = output_sequences
    output["Position"] = output_positions
    output["Validated PSMs"] = output_validated_psms
    output["Validated Protein Groups"] = output_validated_PG
    output["Processed Protein Groups"] = output_processed_PG

    output = output.merge(SC_df, how="left", on="Protein")

    # the below part is not needed, we will keep the proteins which exist in different protein groups
    # seq_count = []
    # for i in range(len(output_proteins)):
    #     count = 0
    #     for j in range(i, len(output_proteins)):
    #         if output_proteins[i] == output_proteins[j] and output_sequences[i] == output_sequences[j]:
    #             count += 1
    #     seq_count.append(count)

    # output['Protein Sequence Counts'] = seq_count
    # output = output[output['Protein Sequence Counts'] == 1]

    groupby_sequence = output.groupby(["Sequence"]).count()["Protein"]
    seq_count = pd.DataFrame()
    seq_count["Sequence"] = groupby_sequence.index.to_list()
    seq_count["#Proteins"] = groupby_sequence.values
    output = output.merge(seq_count, how="left", on="Sequence")

    output["PXD ID"] = pxd_id
    output["PRIDE Link"] = "ebi.ac.uk/pride/archive/projects/" + pxd_id

    save_columns = [
        "Protein",
        "Sequence",
        "Position",
        "#Proteins",
        "Validated Protein Groups",
        "Validated PSMs",
        "Spectrum Counting",
        "Processed Protein Groups",
        "PXD ID",
        "PRIDE Link",
    ]
    output[save_columns].to_csv(save_file_name, index=False)
